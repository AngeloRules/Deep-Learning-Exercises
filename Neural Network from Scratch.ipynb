{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0ad700bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "956e5b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('customer.csv')\n",
    "data['age'] = data['age']/100\n",
    "x = data[['age','affordibility']]\n",
    "y = data['bought_insurance']\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "e30c363a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomNN(object):\n",
    "    \n",
    "    def __init__ (self):\n",
    "        self.w1 = 1\n",
    "        self.w2 = 1\n",
    "        self.bias = 0\n",
    "        self.loss = None\n",
    "        \n",
    "    def _log_loss(self,y_pred,y_true): #our cost function\n",
    "        epsilon = 1e-15\n",
    "        y_predicted_new = [max(i,epsilon) for i in y_pred]\n",
    "        y_predicted_new = [max(i,epsilon) for i in y_predicted_new]\n",
    "        y_predicted_new = np.array(y_predicted_new)\n",
    "        return -np.mean(y_true*np.log(y_predicted_new)+(1-y_true)*np.log(1-y_predicted_new))\n",
    "    \n",
    "    def _sigmoid_num(self,x): #our activation function\n",
    "        return(1/(1+np.exp(-x)))\n",
    "    \n",
    "    def fit(self,x,y,epoch,learning_rate=0.01):\n",
    "        self.w1,self.w2,self.bias,self.loss = self._gradient_descent(age=x['age'],affordibility=x['affordibility'],y_true=y,epoch=epoch,learning_rate=learning_rate)\n",
    "        return self.loss\n",
    "    \n",
    "    def predict(self,x):\n",
    "        weighted_sum = self.w1 * x['age'] + self.w2 * x['affordibility'] + self.bias\n",
    "        prediction = self._sigmoid_num(weighted_sum)\n",
    "        return prediction\n",
    "        \n",
    "    \n",
    "    def _gradient_descent(self,age, affordibility,y_true,epoch,learning_rate=0.01):\n",
    "        \"\"\"\n",
    "        A function to implement a gradient descent algorithm\n",
    "    \n",
    "        age(numpy-array): the column representing the age column of the data set\n",
    "        affordibility(numpy-array): the column representing the affordibility of the data set\n",
    "        y_true(numpy-array): the column representing the bought insurance column\n",
    "        learning_rate(int): the learning rate of choice\n",
    "        \"\"\"\n",
    "        w1,w2,bias = 1,1,0\n",
    "        length = len(age)\n",
    "    \n",
    "        for i in range(epoch):\n",
    "            weighted_sum = w1*age + w2*affordibility + bias\n",
    "            y_predicted = self._sigmoid_num(weighted_sum)\n",
    "            loss = self._log_loss(y_predicted, y_true)\n",
    "            weight1_derivative = (1/length)*np.dot(np.transpose(age),(y_predicted-y_true))\n",
    "            weight2_derivative = (1/length)*np.dot(np.transpose(affordibility),(y_predicted-y_true))\n",
    "            bias_derivative = np.mean(y_predicted-y_true)\n",
    "\n",
    "            w1 = w1 - learning_rate * weight1_derivative\n",
    "            w2 = w2 - learning_rate * weight2_derivative\n",
    "            bias = bias - learning_rate * bias_derivative\n",
    "\n",
    "            print(f'loss: {loss} weight 1 :{w1} weight 2 :{w2}  bias: {bias} ===> epoch {i+1}')\n",
    "    \n",
    "        return w1,w2,bias,loss\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "978bd64f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.7274650439419775 weight 1 :0.9874336099924031 weight 2 :0.9172905161941962  bias: -0.10303401705925051 ===> epoch 1\n",
      "loss: 0.694858410680056 weight 1 :0.9806934557038988 weight 2 :0.8468926579079777  bias: -0.190784200759533 ===> epoch 2\n",
      "loss: 0.6714927915978994 weight 1 :0.9792922818721587 weight 2 :0.7879084830544909  bias: -0.26459744053692674 ===> epoch 3\n",
      "loss: 0.6551302364965896 weight 1 :0.9825999430875608 weight 2 :0.7390815677392758  bias: -0.3261581182867963 ===> epoch 4\n",
      "loss: 0.6438116163390121 weight 1 :0.989933758214478 weight 2 :0.6990042946680691  bias: -0.3772589741340215 ===> epoch 5\n",
      "loss: 0.6359817104568908 weight 1 :1.0006273195212785 weight 2 :0.6662784153763133  bias: -0.4196307103817811 ===> epoch 6\n",
      "loss: 0.6304911325581658 weight 1 :1.0140725866847546 weight 2 :0.6396152735558811  bias: -0.4548405818963818 ===> epoch 7\n",
      "loss: 0.6265334662105362 weight 1 :1.029739456513794 weight 2 :0.6178844491020673  bias: -0.4842476489590485 ===> epoch 8\n",
      "loss: 0.623563766875363 weight 1 :1.0471799937383188 weight 2 :0.6001269428390829  bias: -0.5089958330136998 ===> epoch 9\n",
      "loss: 0.6212235814833195 weight 1 :1.066023831163946 weight 2 :0.5855476972553202  bias: -0.5300282427146509 ===> epoch 10\n",
      "loss: 0.6192816479326795 weight 1 :1.0859693792816776 weight 2 :0.5734980657715326  bias: -0.5481112171139411 ===> epoch 11\n",
      "loss: 0.6175908264108328 weight 1 :1.106773705458665 weight 2 :0.5634548078790768  bias: -0.563861087543322 ===> epoch 12\n",
      "loss: 0.6160584352737832 weight 1 :1.1282426466618436 weight 2 :0.5549992367282641  bias: -0.5777699076821414 ===> epoch 13\n",
      "loss: 0.6146265179529959 weight 1 :1.150221897441989 weight 2 :0.5477982688504685  bias: -0.590228429431426 ===> epoch 14\n",
      "loss: 0.6132590220080452 weight 1 :1.1725893401048055 weight 2 :0.5415880381436783  bias: -0.6015457557518497 ===> epoch 15\n",
      "loss: 0.6119336043052013 weight 1 :1.195248632128153 weight 2 :0.5361601557980701  bias: -0.6119657024240804 ===> epoch 16\n",
      "loss: 0.6106364533303424 weight 1 :1.2181239460001716 weight 2 :0.5313504179763847  bias: -0.6216801785330274 ===> epoch 17\n",
      "loss: 0.6093590448396102 weight 1 :1.2411557102621866 weight 2 :0.5270296509674701  bias: -0.6308399959277029 ===> epoch 18\n",
      "loss: 0.6080961211621253 weight 1 :1.2642971926242468 weight 2 :0.5230963596733014  bias: -0.639563527060539 ===> epoch 19\n",
      "loss: 0.6068444381886603 weight 1 :1.2875117766048132 weight 2 :0.5194708642846894  bias: -0.6479435970075302 ===> epoch 20\n",
      "loss: 0.605601990925445 weight 1 :1.3107708012957133 weight 2 :0.5160906469675945  bias: -0.6560529453506394 ===> epoch 21\n",
      "loss: 0.6043675359902634 weight 1 :1.3340518538555604 weight 2 :0.5129066722721215  bias: -0.6639485404588699 ===> epoch 22\n",
      "loss: 0.6031402977232277 weight 1 :1.3573374234012054 weight 2 :0.5098804853721906  bias: -0.6716749789603564 ===> epoch 23\n",
      "loss: 0.6019197875462458 weight 1 :1.3806138419018958 weight 2 :0.5069819283415803  bias: -0.6792671594788715 ===> epoch 24\n",
      "loss: 0.6007056930388119 weight 1 :1.4038704521256231 weight 2 :0.5041873455706759  bias: -0.6867523826714732 ===> epoch 25\n",
      "loss: 0.5994978098710594 weight 1 :1.4270989546980068 weight 2 :0.5014781751778781  bias: -0.6941519989516906 ===> epoch 26\n",
      "loss: 0.5982960000555039 weight 1 :1.4502928961530872 weight 2 :0.49883984435154105  bias: -0.7014827003072343 ===> epoch 27\n",
      "loss: 0.5971001663489883 weight 1 :1.4734472677887442 weight 2 :0.4962609036091632  bias: -0.7087575324910195 ===> epoch 28\n",
      "loss: 0.5959102365597736 weight 1 :1.4965581914957498 weight 2 :0.493732348632092  bias: -0.7159866877645146 ===> epoch 29\n",
      "loss: 0.5947261539274341 weight 1 :1.519622673791209 weight 2 :0.49124708922727217  bias: -0.7231781255685406 ===> epoch 30\n",
      "loss: 0.5935478712251583 weight 1 :1.5426384132998756 weight 2 :0.48879953360702016  bias: -0.7303380583562649 ===> epoch 31\n",
      "loss: 0.5923753471435105 weight 1 :1.565603650097218 weight 2 :0.4863852630061331  bias: -0.7374713318171379 ===> epoch 32\n",
      "loss: 0.5912085440725002 weight 1 :1.5885170478266457 weight 2 :0.4840007770385092  bias: -0.7445817224144602 ===> epoch 33\n",
      "loss: 0.5900474267407368 weight 1 :1.6113776014685472 weight 2 :0.4816432944305142  bias: -0.75167217020099 ===> epoch 34\n",
      "loss: 0.5888919613800266 weight 1 :1.6341845651823184 weight 2 :0.4793105970953625  bias: -0.7587449609836916 ===> epoch 35\n",
      "loss: 0.5877421152121638 weight 1 :1.65693739585351 weight 2 :0.4770009081235089  bias: -0.7658018688547786 ===> epoch 36\n",
      "loss: 0.586597856133358 weight 1 :1.6796357089274427 weight 2 :0.4747127963109233  bias: -0.7728442677125218 ===> epoch 37\n",
      "loss: 0.5854591525199423 weight 1 :1.702279243854215 weight 2 :0.4724451014508696  bias: -0.7798732185202273 ===> epoch 38\n",
      "loss: 0.5843259731085392 weight 1 :1.7248678370522448 weight 2 :0.4701968758707486  bias: -0.7868895375836327 ===> epoch 39\n",
      "loss: 0.5831982869219763 weight 1 :1.7474014007531675 weight 2 :0.46796733867875295  bias: -0.7938938499777928 ===> epoch 40\n",
      "loss: 0.582076063223326 weight 1 :1.7698799064474815 weight 2 :0.4657558399545509  bias: -0.8008866313552486 ===> epoch 41\n",
      "loss: 0.5809592714872541 weight 1 :1.792303371929284 weight 2 :0.4635618327202958  bias: -0.8078682406636715 ===> epoch 42\n",
      "loss: 0.5798478813820342 weight 1 :1.8146718511566418 weight 2 :0.46138485099930265  bias: -0.8148389457507379 ===> epoch 43\n",
      "loss: 0.57874186275814 weight 1 :1.8369854263148029 weight 2 :0.4592244926382237  bias: -0.8217989434034119 ===> epoch 44\n",
      "loss: 0.577641185640904 weight 1 :1.859244201602937 weight 2 :0.4570804058568021  bias: -0.8287483750320053 ===> epoch 45\n",
      "loss: 0.5765458202256941 weight 1 :1.8814482983694796 weight 2 :0.45495227871476024  bias: -0.8356873389459368 ===> epoch 46\n",
      "loss: 0.575455736874653 weight 1 :1.903597851302798 weight 2 :0.45283983086174484  bias: -0.8426158999620382 ===> epoch 47\n",
      "loss: 0.5743709061144089 weight 1 :1.9256930054477468 weight 2 :0.45074280707421543  bias: -0.8495340969250643 ===> epoch 48\n",
      "loss: 0.5732912986343967 weight 1 :1.9477339138686214 weight 2 :0.4486609721910809  bias: -0.8564419485939713 ===> epoch 49\n",
      "loss: 0.5722168852855558 weight 1 :1.9697207358180744 weight 2 :0.44659410714431336  bias: -0.8633394582488887 ===> epoch 50\n",
      "loss: 0.5711476370792709 weight 1 :1.9916536353021141 weight 2 :0.4445420058468146  bias: -0.8702266172965443 ===> epoch 51\n",
      "loss: 0.570083525186463 weight 1 :2.013532779955199 weight 2 :0.44250447275148336  bias: -0.8771034080915268 ===> epoch 52\n",
      "loss: 0.5690245209367771 weight 1 :2.035358340158141 weight 2 :0.44048132093585995  bias: -0.8839698061435379 ===> epoch 53\n",
      "loss: 0.5679705958178307 weight 1 :2.0571304883461523 weight 2 :0.4384723705983594  bias: -0.8908257818438218 ===> epoch 54\n",
      "loss: 0.5669217214745029 weight 1 :2.078849398465815 weight 2 :0.43647744787685966  bias: -0.8976713018150377 ===> epoch 55\n",
      "loss: 0.5658778697082483 weight 1 :2.1005152455487104 weight 2 :0.4344963839197834  bias: -0.9045063299662076 ===> epoch 56\n",
      "loss: 0.564839012476426 weight 1 :2.1221282053764408 weight 2 :0.4325290141549744  bias: -0.9113308283166531 ===> epoch 57\n",
      "loss: 0.5638051218916421 weight 1 :2.143688454217273 weight 2 :0.4305751777135367  bias: -0.9181447576389745 ===> epoch 58\n",
      "loss: 0.5627761702210952 weight 1 :2.165196168618912 weight 2 :0.42863471697509503  bias: -0.9249480779602639 ===> epoch 59\n",
      "loss: 0.5617521298859302 weight 1 :2.18665152524528 weight 2 :0.42670747720820623  bias: -0.9317407489522546 ===> epoch 60\n",
      "loss: 0.5607329734605889 weight 1 :2.2080547007478017 weight 2 :0.42479330628534673  bias: -0.9385227302344499 ===> epoch 61\n",
      "loss: 0.5597186736721694 weight 1 :2.229405871663758 weight 2 :0.42289205445635775  bias: -0.9452939816090697 ===> epoch 62\n",
      "loss: 0.5587092033997787 weight 1 :2.2507052143358752 weight 2 :0.4210035741677216  bias: -0.9520544632425725 ===> epoch 63\n",
      "loss: 0.5577045356738904 weight 1 :2.271952904848592 weight 2 :0.41912771991777686  bias: -0.9588041358053141 ===> epoch 64\n",
      "loss: 0.5567046436757015 weight 1 :2.2931491189774134 weight 2 :0.41726434814012026  bias: -0.9655429605784078 ===> epoch 65\n",
      "loss: 0.5557095007364851 weight 1 :2.3142940321485623 weight 2 :0.4154133171091216  bias: -0.9722708995348835 ===> epoch 66\n",
      "loss: 0.5547190803369498 weight 1 :2.3353878194067192 weight 2 :0.4135744868627913  bias: -0.9789879154007142 ===> epoch 67\n",
      "loss: 0.5537333561065911 weight 1 :2.3564306553891305 weight 2 :0.41174771913926905  bias: -0.9856939717000716 ===> epoch 68\n",
      "loss: 0.5527523018230466 weight 1 :2.3774227143047395 weight 2 :0.4099328773240103  bias: -0.9923890327882319 ===> epoch 69\n",
      "loss: 0.5517758914114496 weight 1 :2.398364169917271 weight 2 :0.40812982640537654  bias: -0.9990730638748139 ===> epoch 70\n",
      "loss: 0.5508040989437807 weight 1 :2.4192551955314454 weight 2 :0.406338432936834  bias: -1.0057460310394515 ===> epoch 71\n",
      "loss: 0.5498368986382229 weight 1 :2.4400959639816704 weight 2 :0.40455856500435033  bias: -1.012407901241551 ===> epoch 72\n",
      "loss: 0.5488742648585112 weight 1 :2.460886647622692 weight 2 :0.40279009219788536  bias: -1.0190586423254266 ===> epoch 73\n",
      "loss: 0.5479161721132844 weight 1 :2.4816274183218088 weight 2 :0.40103288558610967  bias: -1.025698223021828 ===> epoch 74\n",
      "loss: 0.5469625950554367 weight 1 :2.502318447452334 weight 2 :0.39928681769367164  bias: -1.0323266129466573 ===> epoch 75\n",
      "loss: 0.5460135084814686 weight 1 :2.5229599058880527 weight 2 :0.3975517624804806  bias: -1.0389437825975012 ===> epoch 76\n",
      "loss: 0.5450688873308368 weight 1 :2.543551963998482 weight 2 :0.39582759532258827  bias: -1.0455497033484644 ===> epoch 77\n",
      "loss: 0.5441287066853051 weight 1 :2.5640947916447816 weight 2 :0.39411419299434153  bias: -1.0521443474436951 ===> epoch 78\n",
      "loss: 0.5431929417682946 weight 1 :2.5845885581761947 weight 2 :0.39241143365154935  bias: -1.058727687989899 ===> epoch 79\n",
      "loss: 0.5422615679442327 weight 1 :2.6050334324269167 weight 2 :0.39071919681546263  bias: -1.0652996989480834 ===> epoch 80\n",
      "loss: 0.5413345607179052 weight 1 :2.625429582713327 weight 2 :0.38903736335741007  bias: -1.071860355124714 ===> epoch 81\n",
      "loss: 0.5404118957338049 weight 1 :2.6457771768315177 weight 2 :0.3873658154839649  bias: -1.0784096321624335 ===> epoch 82\n",
      "loss: 0.5394935487754824 weight 1 :2.6660763820550746 weight 2 :0.3857044367225473  bias: -1.0849475065304561 ===> epoch 83\n",
      "loss: 0.5385794957648964 weight 1 :2.6863273651330717 weight 2 :0.38405311190738517  bias: -1.0914739555147261 ===> epoch 84\n",
      "loss: 0.537669712761765 weight 1 :2.70653029228825 weight 2 :0.38241172716577504  bias: -1.097988957207915 ===> epoch 85\n",
      "loss: 0.5367641759629159 weight 1 :2.7266853292153606 weight 2 :0.38078016990459584  bias: -1.104492490499309 ===> epoch 86\n",
      "loss: 0.5358628617016385 weight 1 :2.746792641079646 weight 2 :0.3791583287970397  bias: -1.1109845350646343 ===> epoch 87\n",
      "loss: 0.5349657464470349 weight 1 :2.766852392515452 weight 2 :0.3775460937695309  bias: -1.1174650713558518 ===> epoch 88\n",
      "loss: 0.5340728068033722 weight 1 :2.78686474762495 weight 2 :0.3759433559888115  bias: -1.123934080590949 ===> epoch 89\n",
      "loss: 0.5331840195094362 weight 1 :2.80682986997697 weight 2 :0.3743500078491755  bias: -1.1303915447437516 ===> epoch 90\n",
      "loss: 0.532299361437883 weight 1 :2.8267479226059247 weight 2 :0.3727659429598389  bias: -1.1368374465337687 ===> epoch 91\n",
      "loss: 0.5314188095945945 weight 1 :2.846619068010825 weight 2 :0.3711910561324347  bias: -1.143271769416088 ===> epoch 92\n",
      "loss: 0.5305423411180317 weight 1 :2.8664434681543822 weight 2 :0.3696252433686249  bias: -1.1496944975713277 ===> epoch 93\n",
      "loss: 0.5296699332785906 weight 1 :2.8862212844621853 weight 2 :0.36806840184782325  bias: -1.156105615895656 ===> epoch 94\n",
      "loss: 0.5288015634779573 weight 1 :2.9059526778219578 weight 2 :0.36652042991502376  bias: -1.162505109990883 ===> epoch 95\n",
      "loss: 0.5279372092484661 weight 1 :2.9256378085828834 weight 2 :0.3649812270687316  bias: -1.1688929661546301 ===> epoch 96\n",
      "loss: 0.5270768482524559 weight 1 :2.945276836555003 weight 2 :0.36345069394899293  bias: -1.1752691713705812 ===> epoch 97\n",
      "loss: 0.5262204582816291 weight 1 :2.964869921008675 weight 2 :0.3619287323255222  bias: -1.1816337132988166 ===> epoch 98\n",
      "loss: 0.5253680172564109 weight 1 :2.984417220674104 weight 2 :0.3604152450859247  bias: -1.1879865802662355 ===> epoch 99\n",
      "loss: 0.5245195032253096 weight 1 :3.0039188937409267 weight 2 :0.3589101362240135  bias: -1.1943277612570649 ===> epoch 100\n",
      "loss: 0.5236748943642779 weight 1 :3.02337509785786 weight 2 :0.3574133108282197  bias: -1.2006572459034583 ===> epoch 101\n",
      "loss: 0.5228341689760757 weight 1 :3.042785990132408 weight 2 :0.35592467507009484  bias: -1.2069750244761859 ===> epoch 102\n",
      "loss: 0.5219973054896323 weight 1 :3.0621517271306216 weight 2 :0.3544441361929061  bias: -1.2132810878754132 ===> epoch 103\n",
      "loss: 0.521164282459412 weight 1 :3.081472464876918 weight 2 :0.3529716025003227  bias: -1.2195754276215738 ===> epoch 104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.5203350785647801 weight 1 :3.100748358853951 weight 2 :0.351506983345194  bias: -1.2258580358463316 ===> epoch 105\n",
      "loss: 0.519509672609368 weight 1 :3.11997956400253 weight 2 :0.35005018911841823  bias: -1.2321289052836357 ===> epoch 106\n",
      "loss: 0.5186880435204432 weight 1 :3.1391662347215963 weight 2 :0.34860113123790337  bias: -1.2383880292608669 ===> epoch 107\n",
      "loss: 0.5178701703482775 weight 1 :3.1583085248682434 weight 2 :0.3471597221376178  bias: -1.2446354016900756 ===> epoch 108\n",
      "loss: 0.5170560322655174 weight 1 :3.1774065877577877 weight 2 :0.3457258752567325  bias: -1.2508710170593114 ===> epoch 109\n",
      "loss: 0.5162456085665567 weight 1 :3.1964605761638847 weight 2 :0.34429950502885365  bias: -1.2570948704240428 ===> epoch 110\n",
      "loss: 0.5154388786669092 weight 1 :3.215470642318692 weight 2 :0.3428805268713462  bias: -1.2633069573986697 ===> epoch 111\n",
      "loss: 0.514635822102584 weight 1 :3.2344369379130757 weight 2 :0.34146885717474745  bias: -1.269507274148125 ===> epoch 112\n",
      "loss: 0.5138364185294596 weight 1 :3.2533596140968624 weight 2 :0.34006441329227177  bias: -1.2756958173795663 ===> epoch 113\n",
      "loss: 0.5130406477226634 weight 1 :3.2722388214791294 weight 2 :0.3386671135294051  bias: -1.2818725843341578 ===> epoch 114\n",
      "loss: 0.5122484895759501 weight 1 :3.2910747101285414 weight 2 :0.33727687713358984  bias: -1.2880375727789428 ===> epoch 115\n",
      "loss: 0.5114599241010808 weight 1 :3.3098674295737225 weight 2 :0.3358936242840001  bias: -1.294190780998802 ===> epoch 116\n",
      "loss: 0.5106749314272055 weight 1 :3.328617128803671 weight 2 :0.3345172760814065  bias: -1.3003322077885038 ===> epoch 117\n",
      "loss: 0.5098934918002472 weight 1 :3.3473239562682124 weight 2 :0.33314775453813117  bias: -1.3064618524448393 ===> epoch 118\n",
      "loss: 0.5091155855822863 weight 1 :3.365988059878485 weight 2 :0.33178498256809175  bias: -1.3125797147588474 ===> epoch 119\n",
      "loss: 0.5083411932509457 weight 1 :3.3846095870074686 weight 2 :0.3304288839769354  bias: -1.3186857950081254 ===> epoch 120\n",
      "loss: 0.5075702953987814 weight 1 :3.4031886844905443 weight 2 :0.32907938345226156  bias: -1.3247800939492265 ===> epoch 121\n",
      "loss: 0.5068028727326701 weight 1 :3.42172549862609 weight 2 :0.32773640655393405  bias: -1.330862612810142 ===> epoch 122\n",
      "loss: 0.5060389060732019 weight 1 :3.44022017517611 weight 2 :0.32639987970448125  bias: -1.3369333532828709 ===> epoch 123\n",
      "loss: 0.5052783763540722 weight 1 :3.4586728593668963 weight 2 :0.3250697301795853  bias: -1.342992317516073 ===> epoch 124\n",
      "loss: 0.5045212646214777 weight 1 :3.4770836958897235 weight 2 :0.32374588609865906  bias: -1.3490395081078057 ===> epoch 125\n",
      "loss: 0.5037675520335115 weight 1 :3.495452828901573 weight 2 :0.3224282764155111  bias: -1.355074928098346 ===> epoch 126\n",
      "loss: 0.5030172198595625 weight 1 :3.5137804020258896 weight 2 :0.32111683090909815  bias: -1.3610985809630936 ===> epoch 127\n",
      "loss: 0.5022702494797138 weight 1 :3.5320665583533657 weight 2 :0.31981148017436456  bias: -1.367110470605558 ===> epoch 128\n",
      "loss: 0.5015266223841464 weight 1 :3.5503114404427554 weight 2 :0.31851215561316887  bias: -1.3731106013504268 ===> epoch 129\n",
      "loss: 0.5007863201725407 weight 1 :3.568515190321717 weight 2 :0.3172187894252967  bias: -1.3790989779367158 ===> epoch 130\n",
      "loss: 0.5000493245534832 weight 1 :3.5866779494876813 weight 2 :0.31593131459955964  bias: -1.3850756055109983 ===> epoch 131\n",
      "loss: 0.4993156173438729 weight 1 :3.6047998589087475 weight 2 :0.31464966490498014  bias: -1.3910404896207165 ===> epoch 132\n",
      "loss: 0.4985851804683307 weight 1 :3.6228810590246048 weight 2 :0.31337377488206153  bias: -1.3969936362075706 ===> epoch 133\n",
      "loss: 0.4978579959586095 weight 1 :3.6409216897474797 weight 2 :0.3121035798341428  bias: -1.4029350516009875 ===> epoch 134\n",
      "loss: 0.4971340459530084 weight 1 :3.658921890463106 weight 2 :0.3108390158188382  bias: -1.4088647425116685 ===> epoch 135\n",
      "loss: 0.49641331269578526 weight 1 :3.6768818000317203 weight 2 :0.30958001963956083  bias: -1.414782716025212 ===> epoch 136\n",
      "loss: 0.4956957785365752 weight 1 :3.6948015567890806 weight 2 :0.3083265288371294  bias: -1.420688979595816 ===> epoch 137\n",
      "loss: 0.4949814259298075 weight 1 :3.7126812985475057 weight 2 :0.30707848168145885  bias: -1.4265835410400556 ===> epoch 138\n",
      "loss: 0.49427023743412735 weight 1 :3.7305211625969386 weight 2 :0.30583581716333297  bias: -1.4324664085307357 ===> epoch 139\n",
      "loss: 0.4935621957118173 weight 1 :3.7483212857060293 weight 2 :0.3045984749862598  bias: -1.4383375905908202 ===> epoch 140\n",
      "loss: 0.4928572835282217 weight 1 :3.7660818041232393 weight 2 :0.30336639555840844  bias: -1.4441970960874337 ===> epoch 141\n",
      "loss: 0.49215548375117335 weight 1 :3.7838028535779666 weight 2 :0.30213951998462724  bias: -1.4500449342259392 ===> epoch 142\n",
      "loss: 0.49145677935042165 weight 1 :3.8014845692816883 weight 2 :0.3009177900585427  bias: -1.4558811145440864 ===> epoch 143\n",
      "loss: 0.49076115339706305 weight 1 :3.819127085929124 weight 2 :0.29970114825473876  bias: -1.4617056469062353 ===> epoch 144\n",
      "loss: 0.49006858906297296 weight 1 :3.8367305376994167 weight 2 :0.2984895377210155  bias: -1.4675185414976488 ===> epoch 145\n",
      "loss: 0.4893790696202409 weight 1 :3.8542950582573314 weight 2 :0.29728290227072757  bias: -1.4733198088188588 ===> epoch 146\n",
      "loss: 0.48869257844060665 weight 1 :3.8718207807544713 weight 2 :0.2960811863752008  bias: -1.4791094596801018 ===> epoch 147\n",
      "loss: 0.4880090989948981 weight 1 :3.8893078378305104 weight 2 :0.2948843351562276  bias: -1.4848875051958241 ===> epoch 148\n",
      "loss: 0.48732861485247275 weight 1 :3.906756361614443 weight 2 :0.29369229437863914  bias: -1.4906539567792576 ===> epoch 149\n",
      "loss: 0.48665110968066033 weight 1 :3.9241664837258483 weight 2 :0.2925050104429557  bias: -1.4964088261370625 ===> epoch 150\n",
      "loss: 0.4859765672442071 weight 1 :3.94153833527617 weight 2 :0.2913224303781126  bias: -1.50215212526404 ===> epoch 151\n",
      "loss: 0.48530497140472273 weight 1 :3.958872046870012 weight 2 :0.290144501834263  bias: -1.5078838664379104 ===> epoch 152\n",
      "loss: 0.48463630612012965 weight 1 :3.976167748606446 weight 2 :0.28897117307565534  bias: -1.5136040622141593 ===> epoch 153\n",
      "loss: 0.4839705554441139 weight 1 :3.993425570080336 weight 2 :0.28780239297358645  bias: -1.5193127254209493 ===> epoch 154\n",
      "loss: 0.48330770352557856 weight 1 :4.010645640383674 weight 2 :0.28663811099942854  bias: -1.525009869154097 ===> epoch 155\n",
      "loss: 0.482647734608099 weight 1 :4.027828088106931 weight 2 :0.2854782772177301  bias: -1.5306955067721155 ===> epoch 156\n",
      "loss: 0.48199063302938056 weight 1 :4.0449730413404135 weight 2 :0.28432284227939025  bias: -1.5363696518913206 ===> epoch 157\n",
      "loss: 0.4813363832207184 weight 1 :4.062080627675645 weight 2 :0.2831717574149052  bias: -1.542032318381 ===> epoch 158\n",
      "loss: 0.4806849697064584 weight 1 :4.079150974206744 weight 2 :0.2820249744276874  bias: -1.5476835203586476 ===> epoch 159\n",
      "loss: 0.4800363771034626 weight 1 :4.096184207531828 weight 2 :0.28088244568745624  bias: -1.5533232721852563 ===> epoch 160\n",
      "loss: 0.47939059012057467 weight 1 :4.113180453754417 weight 2 :0.2797441241236987  bias: -1.5589515884606766 ===> epoch 161\n",
      "loss: 0.4787475935580881 weight 1 :4.130139838484851 weight 2 :0.27860996321920184  bias: -1.5645684840190337 ===> epoch 162\n",
      "loss: 0.47810737230721756 weight 1 :4.1470624868417225 weight 2 :0.2774799170036541  bias: -1.570173973924205 ===> epoch 163\n",
      "loss: 0.4774699113495711 weight 1 :4.163948523453311 weight 2 :0.276353940047316  bias: -1.5757680734653594 ===> epoch 164\n",
      "loss: 0.47683519575662525 weight 1 :4.180798072459035 weight 2 :0.2752319874547597  bias: -1.581350798152553 ===> epoch 165\n",
      "loss: 0.4762032106892025 weight 1 :4.1976112575109 weight 2 :0.27411401485867637  bias: -1.5869221637123863 ===> epoch 166\n",
      "loss: 0.4755739413969508 weight 1 :4.214388201774976 weight 2 :0.27299997841375145  bias: -1.5924821860837164 ===> epoch 167\n",
      "loss: 0.47494737321782454 weight 1 :4.231129027932861 weight 2 :0.27188983479060636  bias: -1.5980308814134292 ===> epoch 168\n",
      "loss: 0.4743234915775696 weight 1 :4.247833858183168 weight 2 :0.27078354116980674  bias: -1.6035682660522668 ===> epoch 169\n",
      "loss: 0.4737022819892086 weight 1 :4.264502814243014 weight 2 :0.2696810552359366  bias: -1.6090943565507112 ===> epoch 170\n",
      "loss: 0.47308373005252946 weight 1 :4.281136017349513 weight 2 :0.26858233517173735  bias: -1.6146091696549238 ===> epoch 171\n",
      "loss: 0.47246782145357646 weight 1 :4.297733588261287 weight 2 :0.2674873396523117  bias: -1.6201127223027405 ===> epoch 172\n",
      "loss: 0.47185454196414245 weight 1 :4.314295647259969 weight 2 :0.26639602783939137  bias: -1.6256050316197193 ===> epoch 173\n",
      "loss: 0.47124387744126506 weight 1 :4.330822314151726 weight 2 :0.26530835937566843  bias: -1.6310861149152438 ===> epoch 174\n",
      "loss: 0.470635813826722 weight 1 :4.347313708268781 weight 2 :0.2642242943791894  bias: -1.6365559896786788 ===> epoch 175\n",
      "loss: 0.4700303371465335 weight 1 :4.3637699484709405 weight 2 :0.2631437934378116  bias: -1.6420146735755783 ===> epoch 176\n",
      "loss: 0.469427433510462 weight 1 :4.38019115314713 weight 2 :0.26206681760372136  bias: -1.647462184443946 ===> epoch 177\n",
      "loss: 0.46882708911151744 weight 1 :4.396577440216935 weight 2 :0.2609933283880134  bias: -1.6528985402905474 ===> epoch 178\n",
      "loss: 0.468229290225463 weight 1 :4.412928927132147 weight 2 :0.25992328775533063  bias: -1.6583237592872717 ===> epoch 179\n",
      "loss: 0.46763402321032427 weight 1 :4.429245730878313 weight 2 :0.258856658118564  bias: -1.6637378597675456 ===> epoch 180\n",
      "loss: 0.46704127450590033 weight 1 :4.4455279679762905 weight 2 :0.25779340233361203  bias: -1.669140860222796 ===> epoch 181\n",
      "loss: 0.46645103063327653 weight 1 :4.461775754483805 weight 2 :0.25673348369419885  bias: -1.674532779298961 ===> epoch 182\n",
      "loss: 0.4658632781943402 weight 1 :4.477989205997014 weight 2 :0.25567686592675093  bias: -1.679913635793052 ===> epoch 183\n",
      "loss: 0.4652780038712987 weight 1 :4.494168437652078 weight 2 :0.2546235131853314  bias: -1.6852834486497605 ===> epoch 184\n",
      "loss: 0.46469519442619905 weight 1 :4.510313564126725 weight 2 :0.25357339004663143  bias: -1.6906422369581158 ===> epoch 185\n",
      "loss: 0.4641148367004508 weight 1 :4.526424699641828 weight 2 :0.2525264615050187  bias: -1.6959900199481872 ===> epoch 186\n",
      "loss: 0.4635369176143497 weight 1 :4.542501957962981 weight 2 :0.2514826929676413  bias: -1.7013268169878344 ===> epoch 187\n",
      "loss: 0.46296142416660574 weight 1 :4.558545452402081 weight 2 :0.25044205024958793  bias: -1.7066526475795019 ===> epoch 188\n",
      "loss: 0.46238834343387186 weight 1 :4.574555295818909 weight 2 :0.2494044995691025  bias: -1.711967531357061 ===> epoch 189\n",
      "loss: 0.46181766257027496 weight 1 :4.5905316006227155 weight 2 :0.2483700075428535  bias: -1.7172714880826951 ===> epoch 190\n",
      "loss: 0.4612493688069506 weight 1 :4.60647447877381 weight 2 :0.24733854118125723  bias: -1.7225645376438294 ===> epoch 191\n",
      "loss: 0.4606834494515777 weight 1 :4.62238404178515 weight 2 :0.24631006788385426  bias: -1.7278467000501054 ===> epoch 192\n",
      "loss: 0.4601198918879181 weight 1 :4.63826040072393 weight 2 :0.2452845554347389  bias: -1.7331179954303977 ===> epoch 193\n",
      "loss: 0.45955868357535634 weight 1 :4.654103666213181 weight 2 :0.24426197199804092  bias: -1.738378444029874 ===> epoch 194\n",
      "loss: 0.45899981204844276 weight 1 :4.66991394843336 weight 2 :0.24324228611345897  bias: -1.7436280662070973 ===> epoch 195\n",
      "loss: 0.45844326491643894 weight 1 :4.685691357123949 weight 2 :0.2422254666918453  bias: -1.7488668824311704 ===> epoch 196\n",
      "loss: 0.4578890298628641 weight 1 :4.701436001585056 weight 2 :0.2412114830108412  bias: -1.7540949132789205 ===> epoch 197\n",
      "loss: 0.4573370946450456 weight 1 :4.717147990679005 weight 2 :0.2402003047105626  bias: -1.7593121794321258 ===> epoch 198\n",
      "loss: 0.4567874470936705 weight 1 :4.732827432831946 weight 2 :0.23919190178933547  bias: -1.7645187016747814 ===> epoch 199\n",
      "loss: 0.4562400751123403 weight 1 :4.748474436035446 weight 2 :0.2381862445994801  bias: -1.769714500890406 ===> epoch 200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4562400751123403"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CustomNN()\n",
    "model.fit(x=x_train,y=y_train,epoch=200,learning_rate=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "0b01b65f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23    0.646865\n",
       "9     0.796578\n",
       "3     0.668075\n",
       "21    0.369326\n",
       "1     0.358335\n",
       "6     0.698875\n",
       "dtype: float64"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
