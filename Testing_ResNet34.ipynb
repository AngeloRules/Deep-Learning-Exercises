{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "d64b2673",
      "metadata": {
        "id": "d64b2673"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "38fffd7d",
      "metadata": {
        "id": "38fffd7d"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "efc3d1c5",
      "metadata": {
        "id": "efc3d1c5"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "897c63b6",
      "metadata": {
        "id": "897c63b6"
      },
      "outputs": [],
      "source": [
        "import PIL.Image as Image\n",
        "import cv2\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "1e37eac4",
      "metadata": {
        "id": "1e37eac4"
      },
      "outputs": [],
      "source": [
        "data_source = 'https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz'\n",
        "flowers_data = tf.keras.utils.get_file('flower_photos',origin=data_source,cache_dir='.',untar=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "417ffb44",
      "metadata": {
        "id": "417ffb44"
      },
      "outputs": [],
      "source": [
        "import pathlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "baa0f95e",
      "metadata": {
        "id": "baa0f95e"
      },
      "outputs": [],
      "source": [
        "flowers_data = pathlib.Path(flowers_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "6cc8bb29",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cc8bb29",
        "outputId": "e59b292c-c91e-47c1-8f57-ffcaf56b1315"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3670"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "len(list(flowers_data.glob('*/*.jpg')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "82019c3e",
      "metadata": {
        "id": "82019c3e"
      },
      "outputs": [],
      "source": [
        "flower_images_dict = {\n",
        "    'dandelion': list(flowers_data.glob('dandelion/*')),\n",
        "    'roses': list(flowers_data.glob('roses/*')),\n",
        "    'tulips': list(flowers_data.glob('tulips/*')),\n",
        "    'sunflowers': list(flowers_data.glob('sunflowers/*')),\n",
        "    'daisy': list(flowers_data.glob('daisy/*')),\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "a1cc5e94",
      "metadata": {
        "id": "a1cc5e94"
      },
      "outputs": [],
      "source": [
        "flower_dict_labels = {\n",
        "    'dandelion':0,\n",
        "    'roses':1,\n",
        "    'tulips':2,\n",
        "    'sunflowers':3,\n",
        "    'daisy':4\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "335671d0",
      "metadata": {
        "id": "335671d0"
      },
      "outputs": [],
      "source": [
        "x,y = [],[]\n",
        "\n",
        "for flower_name,images in flower_images_dict.items():\n",
        "  for image in images:\n",
        "    img = cv2.imread(str(image))\n",
        "    resized_image = cv2.resize(img,(224,224))\n",
        "    x.append(resized_image)\n",
        "    y.append(flower_dict_labels[flower_name])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "e3b57516",
      "metadata": {
        "id": "e3b57516"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "5abfffbf",
      "metadata": {
        "id": "5abfffbf"
      },
      "outputs": [],
      "source": [
        "x = np.array(x)\n",
        "y = np.array(y) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "0f940590",
      "metadata": {
        "id": "0f940590"
      },
      "outputs": [],
      "source": [
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "b2eb7e8e",
      "metadata": {
        "id": "b2eb7e8e"
      },
      "outputs": [],
      "source": [
        "x_train_scaled = np.divide(x_train,255)\n",
        "x_test_scaled = np.divide(x_test,255)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Conv2D(layers.Layer):\n",
        "\n",
        "    def __init__(self,kernel_size,padding,strides,filters,activation):\n",
        "        super().__init__()\n",
        "        self.conv = layers.Conv2D(\n",
        "            kernel_size=kernel_size,padding=padding,\n",
        "            strides=strides,filters=filters,activation=activation\n",
        "        )\n",
        "        self.batch_norm = layers.BatchNormalization()\n",
        "\n",
        "    def call(self,input_tensor,training=True):\n",
        "        x = self.conv(input_tensor)\n",
        "        x = self.batch_norm(x,training)\n",
        "        return x "
      ],
      "metadata": {
        "id": "DbWQeUuw7YOl"
      },
      "id": "DbWQeUuw7YOl",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNetBlock(layers.Layer):\n",
        "\n",
        "    def __init__(self,channels,stride=1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.skip_dotted = (stride != 1)\n",
        "        self.conv1 = Conv2D((3,3),'same',stride,channels,'relu')\n",
        "        self.conv2 = Conv2D(kernel_size=(3,3),padding='same',filters=channels,activation='relu',strides=1)\n",
        "        if self.skip_dotted:\n",
        "            self.conv3 = Conv2D(filters=channels,kernel_size=(1,1),strides=stride,padding='valid',activation='relu')\n",
        "\n",
        "    \n",
        "    def call(self, input_tensor):\n",
        "        x = self.conv1(input_tensor)\n",
        "        x = tf.nn.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        if self.skip_dotted:\n",
        "            input_tensor = self.conv3(input_tensor)\n",
        "        x = layers.add([input_tensor, x])\n",
        "        x = tf.nn.relu(x)\n",
        "        return x "
      ],
      "metadata": {
        "id": "WiHa-VAa6ANc"
      },
      "id": "WiHa-VAa6ANc",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNet34(keras.Model):\n",
        "\n",
        "    def __init__(self,num_classes=5):\n",
        "        super().__init__()\n",
        "        self.conv1  = Conv2D(filters=64,kernel_size=(7,7),strides=2,padding='same',activation='relu')\n",
        "        self.batch_norm = layers.BatchNormalization()\n",
        "        self.relu = layers.ReLU()\n",
        "        self.pool1 = layers.MaxPooling2D(pool_size=(3,3),strides=2)\n",
        "\n",
        "        self.block1_1 = ResNetBlock(64)\n",
        "        self.block1_2 = ResNetBlock(64)\n",
        "        self.block1_3 = ResNetBlock(64)\n",
        "\n",
        "        self.block2_1 = ResNetBlock(128,2)\n",
        "        self.block2_2 = ResNetBlock(128)\n",
        "        self.block2_3 = ResNetBlock(128)\n",
        "        self.block2_4 = ResNetBlock(128)\n",
        "    \n",
        "        self.block3_1 = ResNetBlock(256,2)\n",
        "        self.block3_2 = ResNetBlock(256)\n",
        "        self.block3_3 = ResNetBlock(256)\n",
        "        self.block3_4 = ResNetBlock(256)\n",
        "        self.block3_5 = ResNetBlock(256)\n",
        "        self.block3_6 = ResNetBlock(256)\n",
        "\n",
        "        self.block4_1 = ResNetBlock(512,2)\n",
        "        self.block4_2 = ResNetBlock(512)\n",
        "        self.block4_3 = ResNetBlock(512)\n",
        "\n",
        "        self.pool2 = layers.GlobalAveragePooling2D()\n",
        "        self.fully_connected1 = layers.Dense(512,activation='relu')\n",
        "        self.fully_connected2 = layers.Dense(512,activation='relu')\n",
        "        self.drop_out1 = layers.Dropout(0.5)\n",
        "        self.drop_out2 = layers.Dropout(0.5)\n",
        "        self.classifier = layers.Dense(units=num_classes,activation='softmax') \n",
        "\n",
        "\n",
        "    def call(self,input_tensor,training=True):\n",
        "        x = self.conv1(input_tensor)\n",
        "        x = self.batch_norm(x,training)\n",
        "        x = self.relu(x)\n",
        "        x = self.pool1(x)\n",
        "        #64 filter section\n",
        "        x = self.block1_1(x)\n",
        "        x = self.block1_2(x)\n",
        "        x = self.block1_3(x)\n",
        "\n",
        "        #128 filter section\n",
        "        x = self.block2_1(x)\n",
        "        x = self.block2_2(x)\n",
        "        x = self.block2_3(x)\n",
        "        x = self.block2_4(x)\n",
        "\n",
        "        #256 filter section\n",
        "        x = self.block3_1(x)\n",
        "        x = self.block3_2(x)\n",
        "        x = self.block3_3(x)\n",
        "        x = self.block3_4(x)\n",
        "        x = self.block3_5(x)\n",
        "        x = self.block3_6(x)\n",
        "\n",
        "        #512 filter section\n",
        "        x = self.block4_1(x)\n",
        "        x = self.block4_2(x)\n",
        "        x = self.block4_3(x)\n",
        "        x = self.pool2(x)\n",
        "        \n",
        "        #fully connected layer\n",
        "        x = self.fully_connected1(x)\n",
        "        x = self.drop_out1(x)\n",
        "        x = self.fully_connected2(x)\n",
        "        x = self.drop_out2(x)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "_DWXakSz6EfZ"
      },
      "id": "_DWXakSz6EfZ",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ResNet34(num_classes=5)"
      ],
      "metadata": {
        "id": "7KjuiM-b8B6w"
      },
      "id": "7KjuiM-b8B6w",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    metrics =['accuracy'],\n",
        "    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        ")"
      ],
      "metadata": {
        "id": "ilOtsEGQ8KF2"
      },
      "id": "ilOtsEGQ8KF2",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x_train_scaled,y_train,epochs=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R4dvzR008QXB",
        "outputId": "f7b3c353-881f-4897-c59f-779730c55175"
      },
      "id": "R4dvzR008QXB",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "92/92 [==============================] - 32s 195ms/step - loss: 2.2182 - accuracy: 0.2139\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3c4c5c2910>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PW7Ae4M2eQV",
        "outputId": "11d42c5e-14b6-4f1f-99d2-0e2a3e0c1806"
      },
      "id": "7PW7Ae4M2eQV",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"res_net34\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             multiple                  9728      \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  multiple                 256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " re_lu (ReLU)                multiple                  0         \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  multiple                 0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " res_net_block (ResNetBlock)  multiple                 74368     \n",
            "                                                                 \n",
            " res_net_block_1 (ResNetBloc  multiple                 74368     \n",
            " k)                                                              \n",
            "                                                                 \n",
            " res_net_block_2 (ResNetBloc  multiple                 74368     \n",
            " k)                                                              \n",
            "                                                                 \n",
            " res_net_block_3 (ResNetBloc  multiple                 231296    \n",
            " k)                                                              \n",
            "                                                                 \n",
            " res_net_block_4 (ResNetBloc  multiple                 296192    \n",
            " k)                                                              \n",
            "                                                                 \n",
            " res_net_block_5 (ResNetBloc  multiple                 296192    \n",
            " k)                                                              \n",
            "                                                                 \n",
            " res_net_block_6 (ResNetBloc  multiple                 296192    \n",
            " k)                                                              \n",
            "                                                                 \n",
            " res_net_block_7 (ResNetBloc  multiple                 921344    \n",
            " k)                                                              \n",
            "                                                                 \n",
            " res_net_block_8 (ResNetBloc  multiple                 1182208   \n",
            " k)                                                              \n",
            "                                                                 \n",
            " res_net_block_9 (ResNetBloc  multiple                 1182208   \n",
            " k)                                                              \n",
            "                                                                 \n",
            " res_net_block_10 (ResNetBlo  multiple                 1182208   \n",
            " ck)                                                             \n",
            "                                                                 \n",
            " res_net_block_11 (ResNetBlo  multiple                 1182208   \n",
            " ck)                                                             \n",
            "                                                                 \n",
            " res_net_block_12 (ResNetBlo  multiple                 1182208   \n",
            " ck)                                                             \n",
            "                                                                 \n",
            " res_net_block_13 (ResNetBlo  multiple                 3677696   \n",
            " ck)                                                             \n",
            "                                                                 \n",
            " res_net_block_14 (ResNetBlo  multiple                 4723712   \n",
            " ck)                                                             \n",
            "                                                                 \n",
            " res_net_block_15 (ResNetBlo  multiple                 4723712   \n",
            " ck)                                                             \n",
            "                                                                 \n",
            " global_average_pooling2d (G  multiple                 0         \n",
            " lobalAveragePooling2D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               multiple                  262656    \n",
            "                                                                 \n",
            " dense_1 (Dense)             multiple                  262656    \n",
            "                                                                 \n",
            " dropout (Dropout)           multiple                  0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         multiple                  0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             multiple                  2565      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 21,838,341\n",
            "Trainable params: 21,821,189\n",
            "Non-trainable params: 17,152\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UN54iWnf8gBc"
      },
      "id": "UN54iWnf8gBc",
      "execution_count": 22,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}